from transformers import AutoTokenizer, AutoModelForCausalLM, BertTokenizer, BertForQuestionAnswering
from sparql.query_runner import load_rdf_graph, run_sparql
from bert_rag.bert_with_rag import answer_with_context
import torch

# Chargement du modÃ¨le Mistral fine-tunÃ© avec LoRA
mistral_path = "./models/mistral_sparql_lora"
mistral_tokenizer = AutoTokenizer.from_pretrained(mistral_path, trust_remote_code=True)
mistral_model = AutoModelForCausalLM.from_pretrained(mistral_path, device_map="auto", trust_remote_code=True)

# Chargement du modÃ¨le BERT pour l'Ã©tape RAG
bert_tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
bert_model = BertForQuestionAnswering.from_pretrained("bert-base-uncased")

# Chargement du graphe RDF local
rdf_graph = load_rdf_graph("data/rdf_graph.ttl")

# GÃ©nÃ¨re une requÃªte SPARQL Ã  partir d'une question
def generate_sparql(question):
    prompt = f"Tu es un agent intelligent. GÃ©nÃ¨re une requÃªte SPARQL pour rÃ©pondre Ã  la question suivante : {question}\nRequÃªte SPARQL : "
    inputs = mistral_tokenizer(prompt, return_tensors="pt").to(mistral_model.device)
    outputs = mistral_model.generate(**inputs, max_new_tokens=256)
    sparql_query = mistral_tokenizer.decode(outputs[0], skip_special_tokens=True)

    if "RequÃªte SPARQL :" in sparql_query:
        sparql_query = sparql_query.split("RequÃªte SPARQL :")[-1].strip()
    return sparql_query

# Pipeline RAG complet
def rag_pipeline(question):
    print(f"\nâ“ Question : {question}")

    sparql_query = generate_sparql(question)
    print(f"\nğŸ“¡ RequÃªte SPARQL gÃ©nÃ©rÃ©e :\n{sparql_query}")

    try:
        results = run_sparql(sparql_query, rdf_graph)
        if not results:
            return "âŒ Aucune donnÃ©e trouvÃ©e dans le graphe RDF."
        rdf_context = " ".join(results)
        print(f"\nğŸ“˜ RÃ©sultats RDF : {rdf_context}")
    except Exception as e:
        return f"âš ï¸ Erreur SPARQL : {e}"

    answer = answer_with_context(question, rdf_context)
    return f"\nâœ… RÃ©ponse finale : {answer}"

# Exemple
if __name__ == "__main__":
    question = "Quels moteurs Ã©quipe le Boeing 737 ?"
    final_answer = rag_pipeline(question)
    print(final_answer)
